{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dtc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P3cz2geZ4_z"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# copy your splitdata_train_test function here\n",
        "def splitdata_train_test(data, fraction_training):\n",
        "  np.random.seed(0)\n",
        "  np.random.shuffle(data)\n",
        "  trainRowCount = int(fraction_training*len(data))\n",
        "  return data[0:trainRowCount], data[trainRowCount:len(data)]\n",
        "\n",
        "\n",
        "# copy your generate_features_targets function here\n",
        "def generate_features_targets(data):\n",
        "  # complete the function by calculating the concentrations\n",
        "\n",
        "  targets = data['class']\n",
        "\n",
        "  features = np.empty(shape=(len(data), 13))\n",
        "  features[:, 0] = data['u-g']\n",
        "  features[:, 1] = data['g-r']\n",
        "  features[:, 2] = data['r-i']\n",
        "  features[:, 3] = data['i-z']\n",
        "  features[:, 4] = data['ecc']\n",
        "  features[:, 5] = data['m4_u']\n",
        "  features[:, 6] = data['m4_g']\n",
        "  features[:, 7] = data['m4_r']\n",
        "  features[:, 8] = data['m4_i']\n",
        "  features[:, 9] = data['m4_z']\n",
        "\n",
        "  # fill the remaining 3 columns with concentrations in the u, r and z filters\n",
        "  # concentration in u filter\n",
        "  features[:, 10] = data['petroR50_u']/data['petroR90_u']\n",
        "  # concentration in r filter\n",
        "  features[:, 11] = data['petroR50_r']/data['petroR90_r']\n",
        "  # concentration in z filter\n",
        "  features[:, 12] = data['petroR50_z']/data['petroR90_z']\n",
        "\n",
        "  return features, targets\n",
        "\n",
        "\n",
        "\n",
        "# complete this function by splitting the data set and training a decision tree classifier\n",
        "def dtc_predict_actual(data):\n",
        "  # split the data into training and testing sets using a training fraction of 0.7\n",
        "  train_data, test_data = splitdata_train_test(data, 0.7)\n",
        "  # generate the feature and targets for the training and test sets\n",
        "  train_features, train_targets = generate_features_targets(train_data)\n",
        "  test_features, test_targets = generate_features_targets(test_data)\n",
        "  # i.e. train_features, train_targets, test_features, test_targets\n",
        "  \n",
        "\n",
        "\n",
        "  # instantiate a decision tree classifier\n",
        "  dtc = DecisionTreeClassifier()\n",
        "\n",
        "  # train the classifier with the train_features and train_targets\n",
        "  dtc.fit(train_features, train_targets)\n",
        "\n",
        "  # get predictions for the test_features\n",
        "  predictions = dtc.predict(test_features)\n",
        "  # return the predictions and the test_targets\n",
        "  return predictions, test_targets\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  data = np.load('galaxy_catalogue.npy')\n",
        "    \n",
        "  predicted_class, actual_class = dtc_predict_actual(data)\n",
        "\n",
        "  # Print some of the initial results\n",
        "  print(\"Some initial results...\\n   predicted,  actual\")\n",
        "  for i in range(10):\n",
        "    print(\"{}. {}, {}\".format(i, predicted_class[i], actual_class[i]))\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}